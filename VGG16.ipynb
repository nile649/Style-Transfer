{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from six.moves import urllib\n",
    "import pandas as pd\n",
    "import csv\n",
    "def get_resized_image(img_path, width, height, save=True):\n",
    "    image = Image.open(img_path)\n",
    "    # PIL is column major so you have to swap the places of width and height\n",
    "    image = ImageOps.fit(image, (width, height), Image.ANTIALIAS)\n",
    "    if save:\n",
    "        image_dirs = img_path.split('/')\n",
    "        image_dirs[-1] = 'resized_' + image_dirs[-1]\n",
    "        out_path = '/'.join(image_dirs)\n",
    "        if not os.path.exists(out_path):\n",
    "            image.save(out_path)\n",
    "    image = np.asarray(image, np.float32)\n",
    "    return np.expand_dims(image, 0)\n",
    "\n",
    "def generate_noise_image(content_image, width, height, noise_ratio=0.6):\n",
    "    noise_image = np.random.uniform(-20, 20, (1, height, width, 3)).astype(np.float32)\n",
    "    return noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "\n",
    "def save_image(path, image):\n",
    "    image = image[0]\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)\n",
    "\n",
    "def safe_mkdir(path):\n",
    "    \"\"\" Create a directory if there isn't one already. \"\"\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "\n",
    "class VGG(object):\n",
    "    def __init__(self, input_img):\n",
    "#         utils.download(VGG_DOWNLOAD_LINK, VGG_FILENAME, EXPECTED_BYTES)\n",
    "        self.vgg_layers = scipy.io.loadmat('/home/n/projectdl/data/imagenet-vgg-verydeep-16.mat')['layers']\n",
    "        self.input_img = input_img\n",
    "        self.mean_pixels = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "\n",
    "\n",
    "    def _weights(self, layer_idx, expected_layer_name):\n",
    "        \"\"\" Return the weights and biases at layer_idx already trained by VGG\n",
    "        \"\"\"\n",
    "        W = self.vgg_layers[0][layer_idx][0][0][2][0][0]\n",
    "        b = self.vgg_layers[0][layer_idx][0][0][2][0][1]\n",
    "        layer_name = self.vgg_layers[0][layer_idx][0][0][0][0]\n",
    "        assert layer_name == expected_layer_name\n",
    "        return W, b.reshape(b.size)\n",
    "\n",
    "    def conv2d_relu(self, prev_layer, layer_idx, layer_name):\n",
    "        \"\"\" Return the Conv2D layer with RELU using the weights, \n",
    "        biases from the VGG model at 'layer_idx'.\n",
    "        Don't forget to apply relu to the output from the convolution.\n",
    "        Inputs:\n",
    "            prev_layer: the output tensor from the previous layer\n",
    "            layer_idx: the index to current layer in vgg_layers\n",
    "            layer_name: the string that is the name of the current layer.\n",
    "                        It's used to specify variable_scope.\n",
    "\n",
    "\n",
    "        Note that you first need to obtain W and b from from the corresponding VGG's layer \n",
    "        using the function _weights() defined above.\n",
    "        W and b returned from _weights() are numpy arrays, so you have\n",
    "        to convert them to TF tensors. One way to do it is with tf.constant.\n",
    "\n",
    "        Hint for choosing strides size: \n",
    "            for small images, you probably don't want to skip any pixel\n",
    "        \"\"\"\n",
    "        ###############################\n",
    "        ## TO DO\n",
    "        with tf.variable_scope(layer_name) as scope:\n",
    "            W, b = self._weights(layer_idx, layer_name)\n",
    "            W = tf.constant(W, name='weights')\n",
    "            b = tf.constant(b, name='bias')\n",
    "            conv2d = tf.nn.conv2d(prev_layer, \n",
    "                                filter=W, \n",
    "                                strides=[1, 1, 1, 1], \n",
    "                                padding='SAME')\n",
    "            out = tf.nn.relu(conv2d + b)\n",
    "        ###############################\n",
    "        setattr(self, layer_name, out)\n",
    "\n",
    "    def avgpool(self, prev_layer, layer_name):\n",
    "        \"\"\" Return the average pooling layer. The paper suggests that \n",
    "        average pooling works better than max pooling.\n",
    "        Input:\n",
    "            prev_layer: the output tensor from the previous layer\n",
    "            layer_name: the string that you want to name the layer.\n",
    "                        It's used to specify variable_scope.\n",
    "\n",
    "        Hint for choosing strides and kszie: choose what you feel appropriate\n",
    "        \"\"\"\n",
    "        ###############################\n",
    "        ## TO DO\n",
    "        with tf.variable_scope(layer_name):\n",
    "            out = tf.nn.avg_pool(prev_layer, \n",
    "                                ksize=[1, 2, 2, 1], \n",
    "                                strides=[1, 2, 2, 1],\n",
    "                                padding='SAME')\n",
    "        ###############################\n",
    "        setattr(self, layer_name, out)\n",
    "\n",
    "    def load(self):\n",
    "        self.conv2d_relu(self.input_img, 0, 'conv1_1')\n",
    "        self.conv2d_relu(self.conv1_1, 2, 'conv1_2')\n",
    "        self.avgpool(self.conv1_2, 'avgpool1')\n",
    "        \n",
    "        self.conv2d_relu(self.avgpool1, 5, 'conv2_1')\n",
    "        self.conv2d_relu(self.conv2_1, 7, 'conv2_2')\n",
    "        self.avgpool(self.conv2_2, 'avgpool2')\n",
    "        \n",
    "        self.conv2d_relu(self.avgpool2, 10, 'conv3_1')\n",
    "        self.conv2d_relu(self.conv3_1, 12, 'conv3_2')\n",
    "        self.conv2d_relu(self.conv3_2, 14, 'conv3_3')\n",
    "#         self.conv2d_relu(self.conv3_3, 16, 'conv3_4')\n",
    "        self.avgpool(self.conv3_3, 'avgpool3')\n",
    "        \n",
    "        self.conv2d_relu(self.avgpool3, 17, 'conv4_1')\n",
    "        self.conv2d_relu(self.conv4_1, 19, 'conv4_2')\n",
    "        self.conv2d_relu(self.conv4_2, 21, 'conv4_3')\n",
    "#         self.conv2d_relu(self.conv4_3, 25, 'conv4_4')\n",
    "        self.avgpool(self.conv4_3, 'avgpool4')\n",
    "        \n",
    "        self.conv2d_relu(self.avgpool4, 24, 'conv5_1')\n",
    "        self.conv2d_relu(self.conv5_1, 26, 'conv5_2')\n",
    "        self.conv2d_relu(self.conv5_2, 28, 'conv5_3')\n",
    "#         self.conv2d_relu(self.conv5_3, 34, 'conv5_4')\n",
    "        self.avgpool(self.conv5_3, 'avgpool5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter optimizer6\n",
      "INFO:tensorflow:Summary name content loss is illegal; using content_loss instead.\n",
      "INFO:tensorflow:Summary name style loss is illegal; using style_loss instead.\n",
      "INFO:tensorflow:Summary name total loss is illegal; using total_loss instead.\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 1122390784.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 11\n",
      "1122390800.0\n",
      "Step 1\n",
      "   Sum: 117371546.7\n",
      "   Loss:   9.6\n",
      "   Took: 10.07979154586792 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:30: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 1023766208.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 7\n",
      "1023766200.0\n",
      "Step 2\n",
      "   Sum: 117452986.9\n",
      "   Loss:   8.7\n",
      "   Took: 2.1622161865234375 seconds\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 943747648.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 7\n",
      "943747650.0\n",
      "Step 3\n",
      "   Sum: 117571888.9\n",
      "   Loss:   8.0\n",
      "   Took: 2.1139519214630127 seconds\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 876206592.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 7\n",
      "876206600.0\n",
      "Step 4\n",
      "   Sum: 117710979.4\n",
      "   Loss:   7.4\n",
      "   Took: 2.202561378479004 seconds\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 817115776.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 7\n",
      "817115800.0\n",
      "Step 5\n",
      "   Sum: 117863780.9\n",
      "   Loss:   6.9\n",
      "   Took: 2.1008386611938477 seconds\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 763863808.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 7\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 715160896.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 7\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 670221248.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 7\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 532078976.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 8\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 522959456.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 6\n",
      "522959460.0\n",
      "Step 10\n",
      "   Sum: 119101845.5\n",
      "   Loss:   4.4\n",
      "   Took: 9.740862131118774 seconds\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 491259232.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 7\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 461800512.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 7\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 434874592.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 7\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 427275872.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 6\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 400619616.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 7\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 393652288.000000\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6efa51c5a852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0mmachine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStyleTransfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/n/projectdl/content2.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/home/n/projectdl/color4.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0mmachine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mmachine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-6efa51c5a852>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_iters)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"2nd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/opt/python/training/external_optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, session, feed_dict, fetches, step_callback, loss_callback, **run_kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mpacked_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_packed_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mstep_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         optimizer_kwargs=self.optimizer_kwargs)\n\u001b[0m\u001b[1;32m    208\u001b[0m     var_vals = [\n\u001b[1;32m    209\u001b[0m         \u001b[0mpacked_var_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpacking_slice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpacking_slice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_packing_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/opt/python/training/external_optimizer.py\u001b[0m in \u001b[0;36m_minimize\u001b[0;34m(self, initial_val, loss_grad_func, equality_funcs, equality_grad_funcs, inequality_funcs, inequality_grad_funcs, packed_bounds, step_callback, optimizer_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mminimize_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mminimize_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     message_lines = [\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 487\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/opt/python/training/external_optimizer.py\u001b[0m in \u001b[0;36mloss_grad_func_wrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss_grad_func_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m       \u001b[0;31m# SciPy's L-BFGS-B Fortran implementation requires gradients as doubles.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_grad_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/opt/python/training/external_optimizer.py\u001b[0m in \u001b[0;36meval_func\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       augmented_fetch_vals = session.run(\n\u001b[0;32m--> 278\u001b[0;31m           augmented_fetches, feed_dict=augmented_feed_dict)\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "class StyleTransfer(object):\n",
    "    def __init__(self, content_img, style_img, img_width, img_height,op):\n",
    "       \n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.content_img = get_resized_image(content_img, img_width, img_height)\n",
    "        self.content_img = self.content_img[:,:,:,0:3]\n",
    "        self.style_img = get_resized_image(style_img, img_width, img_height)\n",
    "        self.initial_img = generate_noise_image(self.content_img, img_width, img_height)\n",
    "\n",
    "        ###############################\n",
    "        ## TO DO\n",
    "        ## create global step (gstep) and hyperparameters for the model\n",
    "        self.content_layer = 'conv4_2'\n",
    "        self.style_layers = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\n",
    "        self.content_w = 0.01\n",
    "        self.style_w = 1\n",
    "        self.style_layer_w = [0.5, 1.0, 1.5, 3.0, 4.0] \n",
    "        self.gstep = tf.Variable(0, dtype=tf.int32, \n",
    "                                trainable=False, name='global_step')\n",
    "        \n",
    "        ###############################\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def create_input(self):\n",
    "        '''\n",
    "        We will use one input_img as a placeholder for the content image, \n",
    "        style image, and generated image, because:\n",
    "            1. they have the same dimension\n",
    "            2. we have to extract the same set of features from them\n",
    "        We use a variable instead of a placeholder because we're, at the same time, \n",
    "        training the generated image to get the desirable result.\n",
    "\n",
    "        Note: image height corresponds to number of rows, not columns.\n",
    "        '''\n",
    "        with tf.variable_scope('input') as scope:\n",
    "            self.input_img = tf.get_variable('in_img', \n",
    "                                        shape=([1, self.img_height, self.img_width, 3]),\n",
    "                                        dtype=tf.float32,\n",
    "                                        initializer=tf.zeros_initializer())\n",
    "            \n",
    "    def load_vgg(self):\n",
    "        '''\n",
    "        Load the saved model parameters of VGG-19, using the input_img\n",
    "        as the input to compute the output at each layer of vgg.\n",
    "\n",
    "        During training, VGG-19 mean-centered all images and found the mean pixels\n",
    "        to be [123.68, 116.779, 103.939] along RGB dimensions. We have to subtract\n",
    "        this mean from our images.\n",
    "\n",
    "\n",
    "        On passing any image from content, style, initial image it will create the model for that image\n",
    "        '''\n",
    "        self.vgg = VGG(self.input_img)\n",
    "        self.vgg.load()\n",
    "        self.content_img -= self.vgg.mean_pixels\n",
    "        self.style_img -= self.vgg.mean_pixels\n",
    "        \n",
    "        \n",
    "    def _content_loss(self, P):\n",
    "        ''' Calculate the loss between the feature representation of the\n",
    "        content image and the generated image.\n",
    "        \n",
    "        Inputs: \n",
    "            P: content representation of the content image\n",
    "            F: content representation of the generated image\n",
    "            Read the assignment handout for more details\n",
    "\n",
    "            Note: Don't use the coefficient 0.5 as defined in the paper.\n",
    "            Use the coefficient defined in the assignment handout.\n",
    "        '''\n",
    "        # self.content_loss = None\n",
    "        ###############################\n",
    "        ## TO DO\n",
    "        F = getattr(self.vgg,self.content_layer)\n",
    "        self.content_loss = tf.reduce_sum((F - P) ** 2) / (4.0)\n",
    "\n",
    "        \n",
    "    def _gram_matrix(self, F, N, M):\n",
    "        \"\"\" Create and return the gram matrix for tensor F\n",
    "            Hint: you'll first have to reshape F\n",
    "        \"\"\"\n",
    "        ###############################\n",
    "        ## TO DO\n",
    "        F = tf.reshape(F, (M, N))\n",
    "        return tf.matmul(tf.transpose(F), F)\n",
    "        ###############################\n",
    "\n",
    "        \n",
    "    def _single_style_loss(self, a, g):\n",
    "        \"\"\" Calculate the style loss at a certain layer\n",
    "        Inputs:\n",
    "            a is the feature representation of the style image at that layer\n",
    "            g is the feature representation of the generated image at that layer\n",
    "        Output:\n",
    "            the style loss at a certain layer (which is E_l in the paper)\n",
    "\n",
    "        Hint: 1. you'll have to use the function _gram_matrix()\n",
    "            2. we'll use the same coefficient for style loss as in the paper\n",
    "            3. a and g are feature representation, not gram matrices\n",
    "        \"\"\"\n",
    "        ###############################\n",
    "        ## TO DO\n",
    "        N = a.shape[3] # number of filters\n",
    "        M = a.shape[1] * a.shape[2] # height times width of the feature map\n",
    "        A = self._gram_matrix(a, N, M)\n",
    "        G = self._gram_matrix(g, N, M)\n",
    "        return tf.reduce_sum((G - A) ** 2 / ((2 * N * M) ** 2))\n",
    "\n",
    "    \n",
    "    def _style_loss(self, A):\n",
    "        \"\"\" Calculate the total style loss as a weighted sum \n",
    "        of style losses at all style layers\n",
    "        Hint: you'll have to use _single_style_loss()\n",
    "        \"\"\"\n",
    "        n_layers = len(A)\n",
    "        E = [self._single_style_loss(A[i], getattr(self.vgg, self.style_layers[i])) for i in range(n_layers)]\n",
    "        \n",
    "        ###############################\n",
    "        ## TO DO\n",
    "        self.style_loss = sum([self.style_layer_w[i] * E[i] for i in range(n_layers)])\n",
    "\n",
    "    def losses(self):\n",
    "        with tf.variable_scope('losses') as scope:\n",
    "            with tf.Session() as sess:\n",
    "                # assign content image to the input variable\n",
    "                sess.run(self.input_img.assign(self.content_img)) \n",
    "                gen_img_content = getattr(self.vgg, self.content_layer)\n",
    "#                 content_img_content = sess.run(gen_img_content)\n",
    "            self._content_loss(gen_img_content)\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(self.input_img.assign(self.style_img))\n",
    "                style_layers = sess.run([getattr(self.vgg, layer) for layer in self.style_layers])                              \n",
    "            self._style_loss(style_layers)\n",
    "\n",
    "            ##########################################\n",
    "            ## TO DO: create total loss. \n",
    "            ## Hint: don't forget the weights for the content loss and style loss\n",
    "            self.total_loss = (self.content_w * self.content_loss + self.style_w * self.style_loss)\n",
    "            ##########################################\n",
    "    def optimize(self,op):\n",
    "        ###############################\n",
    "        ## TO DO: create optimizer\n",
    "        if op==1:\n",
    "            self.lr = 2.0\n",
    "            self.opt = tf.train.AdamOptimizer(self.lr).minimize(self.total_loss,global_step=self.gstep)\n",
    "            \n",
    "        elif op==2:\n",
    "            self.lr = 2.0\n",
    "            self.opt = tf.train.AdagradOptimizer(self.lr).minimize(self.total_loss,global_step=self.gstep)\n",
    "        elif op==3:\n",
    "            self.lr = 0.01\n",
    "            self.opt = tf.train.AdadeltaOptimizer(self.lr).minimize(self.total_loss,global_step=self.gstep)\n",
    "        elif op == 4:\n",
    "            self.lr = 2.0\n",
    "            self.opt = tf.train.RMSPropOptimizer(self.lr).minimize(self.total_loss,global_step=self.gstep)\n",
    "        elif op == 5:\n",
    "            self.lr = 0.1\n",
    "            self.opt = tf.train.MomentumOptimizer(self.lr,0.9).minimize(self.total_loss,global_step=self.gstep)\n",
    "        \n",
    "        elif op == 6:\n",
    "            self.opt = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "            self.total_loss, method='L-BFGS-B',\n",
    "            options={'maxiter': 0,'maxfun':1})\n",
    "            self.opt\n",
    "            self.opp = \"2nd\"\n",
    "\n",
    "\n",
    "        ###############################\n",
    "\n",
    "    def create_summary(self):\n",
    "        ###############################\n",
    "        ## TO DO: create summaries for all the losses\n",
    "        ## Hint: don't forget to merge them\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.summary.scalar('content loss', self.content_loss)\n",
    "            tf.summary.scalar('style loss', self.style_loss)\n",
    "            tf.summary.scalar('total loss', self.total_loss)\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "        ###############################\n",
    "\n",
    "\n",
    "    def build(self,op):\n",
    "        self.create_input()\n",
    "        self.load_vgg()\n",
    "        self.losses()\n",
    "        self.optimize(op)\n",
    "        self.create_summary()\n",
    "\n",
    "    def train(self, n_iters):\n",
    "        skip_step = 1\n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            ###############################\n",
    "            ## TO DO: \n",
    "            ## 1. initialize your variables\n",
    "            ## 2. create writer to write your graph\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            writer = tf.summary.FileWriter('graphs/style_stranfer', sess.graph)\n",
    "            ###############################\n",
    "            sess.run(self.input_img.assign(self.initial_img))\n",
    "\n",
    "\n",
    "            ###############################\n",
    "            ## TO DO: \n",
    "            ## 1. create a saver object\n",
    "            ## 2. check if a checkpoint exists, restore the variables\n",
    "            saver = tf.train.Saver()\n",
    "            ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/style_transfer/checkpoint'))\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            ##############################\n",
    "\n",
    "            initial_step = self.gstep.eval()\n",
    "            \n",
    "            start_time = time.time()\n",
    "            for index in range(initial_step, n_iters):\n",
    "                if index >= 5 and index < 20:\n",
    "                    skip_step = 10\n",
    "                elif index >= 20:\n",
    "                    skip_step = 20\n",
    "                \n",
    "                if(self.opp == \"2nd\"):\n",
    "                    self.opt.minimize(sess)\n",
    "                else:\n",
    "                    sess.run(self.opt)\n",
    "\n",
    "                if (index + 1) % skip_step == 0:\n",
    "                    ###############################\n",
    "                    ## TO DO: obtain generated image, loss, and summary\n",
    "                    gen_image, total_loss, summary = sess.run([self.input_img,\n",
    "                                                                self.total_loss,\n",
    "                                                                self.summary_op])\n",
    "                    print(self.style_loss.eval(session=sess))\n",
    "\n",
    "\n",
    "                    ###############################\n",
    "                    \n",
    "                    # add back the mean pixels we subtracted before\n",
    "                    gen_image = gen_image + self.vgg.mean_pixels \n",
    "                    writer.add_summary(summary, global_step=index)\n",
    "                    print('Step {}\\n   Sum: {:5.1f}'.format(index + 1, np.sum(gen_image)))\n",
    "                    print('   Loss: {:5.1f}'.format(total_loss/np.sum(gen_image)))\n",
    "                    print('   Took: {} seconds'.format(time.time() - start_time))\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    filename = 'outputs/%d.png' % (index)\n",
    "                    save_image(filename, gen_image)\n",
    "                    import csv\n",
    "\n",
    "                    myData = [[index,total_loss/np.sum(gen_image)]  ]\n",
    "                    myFile = open('/home/n/projectdl/16lbfgs.csv', 'a')  \n",
    "                    with myFile:  \n",
    "                        writer_ = csv.writer(myFile)\n",
    "                        writer_.writerows(myData)\n",
    "\n",
    "                    if (index + 1) % 20 == 0:\n",
    "                        ###############################\n",
    "                        ## TO DO: save the variables into a checkpoint\n",
    "                        saver.save(sess, 'checkpoints/style_stranfer/style_transfer', index)\n",
    "                        ###############################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#     setup()\n",
    "    op = int(input(\"enter optimizer\"))\n",
    "    machine = StyleTransfer('/home/n/projectdl/content2.jpg', '/home/n/projectdl/color4.jpg',500,500,op)\n",
    "    machine.build(op)\n",
    "    machine.train(500)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/n/projectdl/xt.csv', 'a') as file_handler:\n",
    "    for item in zip(g,j):\n",
    "        file_handler.write(\"{0} {1}\".format(item))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "myData = [[1,8]]\n",
    "myFile = open('/home/n/projectdl/xt.csv', 'a')  \n",
    "with myFile:  \n",
    "    writer = csv.writer(myFile)\n",
    "    writer.writerows(myData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = pd.read_csv('/home/n/projectdl/xt.csv', engine = 'python', names = range(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

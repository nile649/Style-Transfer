{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from six.moves import urllib\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "def get_resized_image(img_path, width, height, save=True):\n",
    "    image = Image.open(img_path)\n",
    "    # PIL is column major so you have to swap the places of width and height\n",
    "    image = ImageOps.fit(image, (width, height), Image.ANTIALIAS)\n",
    "    if save:\n",
    "        image_dirs = img_path.split('/')\n",
    "        image_dirs[-1] = 'resized_' + image_dirs[-1]\n",
    "        out_path = '/'.join(image_dirs)\n",
    "        if not os.path.exists(out_path):\n",
    "            image.save(out_path)\n",
    "    image = np.asarray(image, np.float32)\n",
    "    return np.expand_dims(image, 0)\n",
    "\n",
    "def generate_noise_image(content_image, width, height, noise_ratio=0.6):\n",
    "    noise_image = np.random.uniform(-20, 20, (1, height, width, 3)).astype(np.float32)\n",
    "    return noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "\n",
    "def save_image(path, image):\n",
    "    image = image[0]\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    scipy.misc.imsave(path, image)\n",
    "\n",
    "def safe_mkdir(path):\n",
    "    \"\"\" Create a directory if there isn't one already. \"\"\"\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "\n",
    "class VGG(object):\n",
    "    def __init__(self, input_img):\n",
    "#         utils.download(VGG_DOWNLOAD_LINK, VGG_FILENAME, EXPECTED_BYTES)\n",
    "        self.vgg_layers = scipy.io.loadmat('/home/n/projectdl/data/imagenet-vgg-verydeep-19.mat')['layers']\n",
    "        self.input_img = input_img\n",
    "        self.mean_pixels = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "\n",
    "\n",
    "    def _weights(self, layer_idx, expected_layer_name):\n",
    "        \"\"\" Return the weights and biases at layer_idx already trained by VGG\n",
    "        \"\"\"\n",
    "        W = self.vgg_layers[0][layer_idx][0][0][2][0][0]\n",
    "        b = self.vgg_layers[0][layer_idx][0][0][2][0][1]\n",
    "        layer_name = self.vgg_layers[0][layer_idx][0][0][0][0]\n",
    "        assert layer_name == expected_layer_name\n",
    "        return W, b.reshape(b.size)\n",
    "\n",
    "    def conv2d_relu(self, prev_layer, layer_idx, layer_name):\n",
    "        \"\"\" Return the Conv2D layer with RELU using the weights, \n",
    "        biases from the VGG model at 'layer_idx'.\n",
    "        Don't forget to apply relu to the output from the convolution.\n",
    "        Inputs:\n",
    "            prev_layer: the output tensor from the previous layer\n",
    "            layer_idx: the index to current layer in vgg_layers\n",
    "            layer_name: the string that is the name of the current layer.\n",
    "                        It's used to specify variable_scope.\n",
    "\n",
    "\n",
    "        Note that you first need to obtain W and b from from the corresponding VGG's layer \n",
    "        using the function _weights() defined above.\n",
    "        W and b returned from _weights() are numpy arrays, so you have\n",
    "        to convert them to TF tensors. One way to do it is with tf.constant.\n",
    "\n",
    "        Hint for choosing strides size: \n",
    "            for small images, you probably don't want to skip any pixel\n",
    "        \"\"\"\n",
    "        ###############################\n",
    "        ## TO DO\n",
    "        with tf.variable_scope(layer_name) as scope:\n",
    "            W, b = self._weights(layer_idx, layer_name)\n",
    "            W = tf.constant(W, name='weights')\n",
    "            b = tf.constant(b, name='bias')\n",
    "            conv2d = tf.nn.conv2d(prev_layer, \n",
    "                                filter=W, \n",
    "                                strides=[1, 1, 1, 1], \n",
    "                                padding='SAME')\n",
    "            out = tf.nn.relu(conv2d + b)\n",
    "        ###############################\n",
    "        setattr(self, layer_name, out)\n",
    "\n",
    "    def avgpool(self, prev_layer, layer_name):\n",
    "        \"\"\" Return the average pooling layer. The paper suggests that \n",
    "        average pooling works better than max pooling.\n",
    "        Input:\n",
    "            prev_layer: the output tensor from the previous layer\n",
    "            layer_name: the string that you want to name the layer.\n",
    "                        It's used to specify variable_scope.\n",
    "\n",
    "        Hint for choosing strides and kszie: choose what you feel appropriate\n",
    "        \"\"\"\n",
    "        ###############################\n",
    "        ## TO DO\n",
    "        with tf.variable_scope(layer_name):\n",
    "            out = tf.nn.avg_pool(prev_layer, \n",
    "                                ksize=[1, 2, 2, 1], \n",
    "                                strides=[1, 2, 2, 1],\n",
    "                                padding='SAME')\n",
    "        ###############################\n",
    "        setattr(self, layer_name, out)\n",
    "\n",
    "    def load(self):\n",
    "        self.conv2d_relu(self.input_img, 0, 'conv1_1')\n",
    "        self.conv2d_relu(self.conv1_1, 2, 'conv1_2')\n",
    "        self.avgpool(self.conv1_2, 'avgpool1')\n",
    "        self.conv2d_relu(self.avgpool1, 5, 'conv2_1')\n",
    "        self.conv2d_relu(self.conv2_1, 7, 'conv2_2')\n",
    "        self.avgpool(self.conv2_2, 'avgpool2')\n",
    "        self.conv2d_relu(self.avgpool2, 10, 'conv3_1')\n",
    "        self.conv2d_relu(self.conv3_1, 12, 'conv3_2')\n",
    "        self.conv2d_relu(self.conv3_2, 14, 'conv3_3')\n",
    "        self.conv2d_relu(self.conv3_3, 16, 'conv3_4')\n",
    "        self.avgpool(self.conv3_4, 'avgpool3')\n",
    "        self.conv2d_relu(self.avgpool3, 19, 'conv4_1')\n",
    "        self.conv2d_relu(self.conv4_1, 21, 'conv4_2')\n",
    "        self.conv2d_relu(self.conv4_2, 23, 'conv4_3')\n",
    "        self.conv2d_relu(self.conv4_3, 25, 'conv4_4')\n",
    "        self.avgpool(self.conv4_4, 'avgpool4')\n",
    "        self.conv2d_relu(self.avgpool4, 28, 'conv5_1')\n",
    "        self.conv2d_relu(self.conv5_1, 30, 'conv5_2')\n",
    "        self.conv2d_relu(self.conv5_2, 32, 'conv5_3')\n",
    "        self.conv2d_relu(self.conv5_3, 34, 'conv5_4')\n",
    "        self.avgpool(self.conv5_4, 'avgpool5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter optimizer1\n",
      "INFO:tensorflow:Summary name content loss is illegal; using content_loss instead.\n",
      "INFO:tensorflow:Summary name style loss is illegal; using style_loss instead.\n",
      "INFO:tensorflow:Summary name total loss is illegal; using total_loss instead.\n",
      "10378508000.0\n",
      "Step 1\n",
      "   Sum: 120366222.5\n",
      "   Loss: 10378508288.0\n",
      "   Took: 8.868210077285767 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:31: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9469638000.0\n",
      "Step 2\n",
      "   Sum: 120457418.2\n",
      "   Loss: 9469637632.0\n",
      "   Took: 0.575810432434082 seconds\n",
      "8584993000.0\n",
      "Step 3\n",
      "   Sum: 120549427.5\n",
      "   Loss: 8584992768.0\n",
      "   Took: 0.5433416366577148 seconds\n",
      "7741278700.0\n",
      "Step 4\n",
      "   Sum: 120642545.1\n",
      "   Loss: 7741278720.0\n",
      "   Took: 0.5419623851776123 seconds\n",
      "6956759000.0\n",
      "Step 5\n",
      "   Sum: 120736863.1\n",
      "   Loss: 6956759040.0\n",
      "   Took: 0.5413942337036133 seconds\n",
      "4083765800.0\n",
      "Step 10\n",
      "   Sum: 121229827.1\n",
      "   Loss: 4083765760.0\n",
      "   Took: 1.5297889709472656 seconds\n",
      "2118965400.0\n",
      "Step 20\n",
      "   Sum: 122072982.5\n",
      "   Loss: 2118965376.0\n",
      "   Took: 2.75248646736145 seconds\n",
      "928066700.0\n",
      "Step 40\n",
      "   Sum: 122409709.0\n",
      "   Loss: 928066688.0\n",
      "   Took: 5.635805130004883 seconds\n",
      "568697000.0\n",
      "Step 60\n",
      "   Sum: 122116030.3\n",
      "   Loss: 568697024.0\n",
      "   Took: 6.1074113845825195 seconds\n",
      "402347170.0\n",
      "Step 80\n",
      "   Sum: 121676936.1\n",
      "   Loss: 402347168.0\n",
      "   Took: 6.040081739425659 seconds\n",
      "306891520.0\n",
      "Step 100\n",
      "   Sum: 121266572.3\n",
      "   Loss: 306891520.0\n",
      "   Took: 6.1307854652404785 seconds\n",
      "245012130.0\n",
      "Step 120\n",
      "   Sum: 120898470.1\n",
      "   Loss: 245012128.0\n",
      "   Took: 6.348193645477295 seconds\n",
      "202099250.0\n",
      "Step 140\n",
      "   Sum: 120566315.2\n",
      "   Loss: 202099248.0\n",
      "   Took: 6.100916385650635 seconds\n",
      "170928590.0\n",
      "Step 160\n",
      "   Sum: 120264370.7\n",
      "   Loss: 170928592.0\n",
      "   Took: 6.294201374053955 seconds\n",
      "147374300.0\n",
      "Step 180\n",
      "   Sum: 119986559.9\n",
      "   Loss: 147374304.0\n",
      "   Took: 6.494207382202148 seconds\n",
      "128901390.0\n",
      "Step 200\n",
      "   Sum: 119729360.1\n",
      "   Loss: 128901392.0\n",
      "   Took: 5.989589214324951 seconds\n",
      "114011150.0\n",
      "Step 220\n",
      "   Sum: 119489837.6\n",
      "   Loss: 114011152.0\n",
      "   Took: 6.194427728652954 seconds\n",
      "101813064.0\n",
      "Step 240\n",
      "   Sum: 119265152.8\n",
      "   Loss: 101813064.0\n",
      "   Took: 5.980945825576782 seconds\n",
      "91590930.0\n",
      "Step 260\n",
      "   Sum: 119053887.6\n",
      "   Loss: 91590928.0\n",
      "   Took: 5.66069221496582 seconds\n",
      "82950056.0\n",
      "Step 280\n",
      "   Sum: 118853422.0\n",
      "   Loss: 82950056.0\n",
      "   Took: 5.898628234863281 seconds\n",
      "75557910.0\n",
      "Step 300\n",
      "   Sum: 118661312.8\n",
      "   Loss: 75557912.0\n",
      "   Took: 6.041698217391968 seconds\n",
      "69167820.0\n",
      "Step 320\n",
      "   Sum: 118475524.2\n",
      "   Loss: 69167824.0\n",
      "   Took: 5.896147012710571 seconds\n",
      "63582120.0\n",
      "Step 340\n",
      "   Sum: 118295948.5\n",
      "   Loss: 63582120.0\n",
      "   Took: 6.1640119552612305 seconds\n",
      "58669130.0\n",
      "Step 360\n",
      "   Sum: 118121646.3\n",
      "   Loss: 58669128.0\n",
      "   Took: 6.024240732192993 seconds\n",
      "54305484.0\n",
      "Step 380\n",
      "   Sum: 117951696.0\n",
      "   Loss: 54305484.0\n",
      "   Took: 6.399946928024292 seconds\n",
      "50415880.0\n",
      "Step 400\n",
      "   Sum: 117786400.1\n",
      "   Loss: 50415880.0\n",
      "   Took: 6.199970245361328 seconds\n",
      "46917700.0\n",
      "Step 420\n",
      "   Sum: 117624353.6\n",
      "   Loss: 46917700.0\n",
      "   Took: 6.243923902511597 seconds\n",
      "43754844.0\n",
      "Step 440\n",
      "   Sum: 117465389.4\n",
      "   Loss: 43754844.0\n",
      "   Took: 9.900344848632812 seconds\n",
      "40890668.0\n",
      "Step 460\n",
      "   Sum: 117308154.5\n",
      "   Loss: 40890668.0\n",
      "   Took: 8.420398712158203 seconds\n",
      "38292070.0\n",
      "Step 480\n",
      "   Sum: 117152118.9\n",
      "   Loss: 38292072.0\n",
      "   Took: 8.535871505737305 seconds\n",
      "35932010.0\n",
      "Step 500\n",
      "   Sum: 116997139.8\n",
      "   Loss: 35932008.0\n",
      "   Took: 8.398566246032715 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class StyleTransfer(object):\n",
    "    def __init__(self, content_img, style_img, img_width, img_height,op):\n",
    "       \n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.content_img = get_resized_image(content_img, img_width, img_height)\n",
    "        self.content_img = self.content_img[:,:,:,0:3]\n",
    "        self.style_img = get_resized_image(style_img, img_width, img_height)\n",
    "        self.initial_img = generate_noise_image(self.content_img, img_width, img_height)\n",
    "\n",
    "        ###############################\n",
    "        ## TO DO\n",
    "        ## create global step (gstep) and hyperparameters for the model\n",
    "        self.content_layer = 'conv4_2'\n",
    "        self.style_layers = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\n",
    "        self.content_w = 0.01\n",
    "        self.style_w = 1\n",
    "        self.style_layer_w = [0.5, 1.0, 1.5, 3.0, 4.0] \n",
    "        self.gstep = tf.Variable(0, dtype=tf.int32, \n",
    "                                trainable=False, name='global_step')\n",
    "        \n",
    "        ###############################\n",
    "        self.opp = 'lbfgs'\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def create_input(self):\n",
    "        '''\n",
    "        We will use one input_img as a placeholder for the content image, \n",
    "        style image, and generated image, because:\n",
    "            1. they have the same dimension\n",
    "            2. we have to extract the same set of features from them\n",
    "        We use a variable instead of a placeholder because we're, at the same time, \n",
    "        training the generated image to get the desirable result.\n",
    "\n",
    "        Note: image height corresponds to number of rows, not columns.\n",
    "        '''\n",
    "        with tf.variable_scope('input') as scope:\n",
    "            self.input_img = tf.get_variable('in_img', \n",
    "                                        shape=([1, self.img_height, self.img_width, 3]),\n",
    "                                        dtype=tf.float32,\n",
    "                                        initializer=tf.zeros_initializer())\n",
    "            \n",
    "    def load_vgg(self):\n",
    "        '''\n",
    "        Load the saved model parameters of VGG-19, using the input_img\n",
    "        as the input to compute the output at each layer of vgg.\n",
    "\n",
    "        During training, VGG-19 mean-centered all images and found the mean pixels\n",
    "        to be [123.68, 116.779, 103.939] along RGB dimensions. We have to subtract\n",
    "        this mean from our images.\n",
    "\n",
    "\n",
    "        On passing any image from content, style, initial image it will create the model for that image\n",
    "        '''\n",
    "        self.vgg = VGG(self.input_img)\n",
    "        self.vgg.load()\n",
    "        self.content_img -= self.vgg.mean_pixels\n",
    "        self.style_img -= self.vgg.mean_pixels\n",
    "        \n",
    "        \n",
    "    def _content_loss(self, P):\n",
    "        ''' Calculate the loss between the feature representation of the\n",
    "        content image and the generated image.\n",
    "        \n",
    "        Inputs: \n",
    "            P: content representation of the content image\n",
    "            F: content representation of the generated image\n",
    "            Read the assignment handout for more details\n",
    "\n",
    "            Note: Don't use the coefficient 0.5 as defined in the paper.\n",
    "            Use the coefficient defined in the assignment handout.\n",
    "        '''\n",
    "        # self.content_loss = None\n",
    "        ###############################\n",
    "        ## TO DO\n",
    "        F = getattr(self.vgg,self.content_layer)\n",
    "        self.content_loss = tf.reduce_sum((F - P) ** 2) / (4.0)\n",
    "\n",
    "        \n",
    "    def _gram_matrix(self, F, N, M):\n",
    "        \"\"\" Create and return the gram matrix for tensor F\n",
    "            Hint: you'll first have to reshape F\n",
    "        \"\"\"\n",
    "        ###############################\n",
    "        ## TO DO\n",
    "        F = tf.reshape(F, (M, N))\n",
    "        return tf.matmul(tf.transpose(F), F)\n",
    "        ###############################\n",
    "\n",
    "        \n",
    "    def _single_style_loss(self, a, g):\n",
    "        \"\"\" Calculate the style loss at a certain layer\n",
    "        Inputs:\n",
    "            a is the feature representation of the style image at that layer\n",
    "            g is the feature representation of the generated image at that layer\n",
    "        Output:\n",
    "            the style loss at a certain layer (which is E_l in the paper)\n",
    "\n",
    "        Hint: 1. you'll have to use the function _gram_matrix()\n",
    "            2. we'll use the same coefficient for style loss as in the paper\n",
    "            3. a and g are feature representation, not gram matrices\n",
    "        \"\"\"\n",
    "        ###############################\n",
    "        ## TO DO\n",
    "        N = a.shape[3] # number of filters\n",
    "        M = a.shape[1] * a.shape[2] # height times width of the feature map\n",
    "        A = self._gram_matrix(a, N, M)\n",
    "        G = self._gram_matrix(g, N, M)\n",
    "        return tf.reduce_sum((G - A) ** 2 / ((2 * N * M) ** 2))\n",
    "\n",
    "    \n",
    "    def _style_loss(self, A):\n",
    "        \"\"\" Calculate the total style loss as a weighted sum \n",
    "        of style losses at all style layers\n",
    "        Hint: you'll have to use _single_style_loss()\n",
    "        \"\"\"\n",
    "        n_layers = len(A)\n",
    "        E = [self._single_style_loss(A[i], getattr(self.vgg, self.style_layers[i])) for i in range(n_layers)]\n",
    "        \n",
    "        ###############################\n",
    "        ## TO DO\n",
    "        self.style_loss = sum([self.style_layer_w[i] * E[i] for i in range(n_layers)])\n",
    "\n",
    "    def losses(self):\n",
    "        with tf.variable_scope('losses') as scope:\n",
    "            with tf.Session() as sess:\n",
    "                # assign content image to the input variable\n",
    "                sess.run(self.input_img.assign(self.content_img)) \n",
    "                gen_img_content = getattr(self.vgg, self.content_layer)\n",
    "#                 content_img_content = sess.run(gen_img_content)\n",
    "            self._content_loss(gen_img_content)\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(self.input_img.assign(self.style_img))\n",
    "                style_layers = sess.run([getattr(self.vgg, layer) for layer in self.style_layers])                              \n",
    "            self._style_loss(style_layers)\n",
    "\n",
    "            ##########################################\n",
    "            ## TO DO: create total loss. \n",
    "            ## Hint: don't forget the weights for the content loss and style loss\n",
    "            self.total_loss = self.content_w * self.content_loss + self.style_w * self.style_loss\n",
    "            ##########################################\n",
    "    def optimize(self,op):\n",
    "        ###############################\n",
    "        ## TO DO: create optimizer\n",
    "        if op==1:\n",
    "            self.lr = 2.0\n",
    "            self.opt = tf.train.AdamOptimizer(self.lr).minimize(self.total_loss,global_step=self.gstep)\n",
    "            \n",
    "        elif op==2:\n",
    "            self.lr = 2.0\n",
    "            self.opt = tf.train.AdagradOptimizer(self.lr).minimize(self.total_loss,global_step=self.gstep)\n",
    "        elif op==3:\n",
    "            self.lr = 2.0\n",
    "            self.opt = tf.train.AdadeltaOptimizer(self.lr).minimize(self.total_loss,global_step=self.gstep)\n",
    "        elif op == 4:\n",
    "            self.lr = 2.0\n",
    "            self.opt = tf.train.RMSPropOptimizer(self.lr).minimize(self.total_loss,global_step=self.gstep)\n",
    "        elif op == 5:\n",
    "            self.lr = 0.1\n",
    "            self.opt = tf.train.MomentumOptimizer(self.lr,0.9).minimize(self.total_loss,global_step=self.gstep)\n",
    "        elif op == 6:\n",
    "            self.opt = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "            self.total_loss, method='L-BFGS-B',\n",
    "            options={'maxiter': 0})\n",
    "            self.opt\n",
    "            self.opp = \"2nd\"\n",
    "\n",
    "        ###############################\n",
    "#     def minimize_with_lbfgs(sess):\n",
    "# #     if args.verbose: print('\\nMINIMIZING LOSS USING: L-BFGS OPTIMIZER')\n",
    "# #     init_op = tf.global_variables_initializer()\n",
    "# #     sess.run(init_op)\n",
    "#         sess.run(net['input'].assign(init_img))\n",
    "#         optimizer.minimize(sess)\n",
    "\n",
    "\n",
    "#     def get_optimizer(self):\n",
    "#     #     print_iterations = args.print_iterations if args.verbose else 0\n",
    "#         if self.opp == 'lbfgs':\n",
    "#             self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "#             self.total_loss, method='L-BFGS-B',\n",
    "#             options={'maxiter': 1})\n",
    "#             self.optimizer\n",
    "    def create_summary(self):\n",
    "        ###############################\n",
    "        ## TO DO: create summaries for all the losses\n",
    "        ## Hint: don't forget to merge them\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.summary.scalar('content loss', self.content_loss)\n",
    "            tf.summary.scalar('style loss', self.style_loss)\n",
    "            tf.summary.scalar('total loss', self.total_loss)\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "        ###############################\n",
    "\n",
    "\n",
    "    def build(self,op):\n",
    "        self.create_input()\n",
    "        self.load_vgg()\n",
    "        self.losses()\n",
    "        self.optimize(op)\n",
    "#         self.get_optimizer()\n",
    "        self.create_summary()\n",
    "\n",
    "    def train(self, n_iters):\n",
    "        skip_step = 1\n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            ###############################\n",
    "            ## TO DO: \n",
    "            ## 1. initialize your variables\n",
    "            ## 2. create writer to write your graph\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            writer = tf.summary.FileWriter('graphs/style_stranfer', sess.graph)\n",
    "            ###############################\n",
    "            sess.run(self.input_img.assign(self.initial_img))\n",
    "\n",
    "\n",
    "            ###############################\n",
    "            ## TO DO: \n",
    "            ## 1. create a saver object\n",
    "            ## 2. check if a checkpoint exists, restore the variables\n",
    "            saver = tf.train.Saver()\n",
    "            ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/style_transfer/checkpoint'))\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            ##############################\n",
    "\n",
    "            initial_step = self.gstep.eval()\n",
    "            \n",
    "            start_time = time.time()\n",
    "            for index in range(initial_step, n_iters):\n",
    "                if index >= 5 and index < 20:\n",
    "                    skip_step = 10\n",
    "                elif index >= 20:\n",
    "                    skip_step = 20\n",
    "                if(self.opp == \"2nd\"):\n",
    "                    self.opt.minimize(sess)\n",
    "                else:\n",
    "                    sess.run(self.opt)\n",
    "                \n",
    "                \n",
    "                if (index + 1) % skip_step == 0:\n",
    "                    ###############################\n",
    "                    ## TO DO: obtain generated image, loss, and summary\n",
    "                    gen_image, total_loss, summary = sess.run([self.input_img,\n",
    "                                                                self.total_loss,\n",
    "                                                                self.summary_op])\n",
    "                    print(self.style_loss.eval(session=sess))\n",
    "\n",
    "\n",
    "                    ###############################\n",
    "                    \n",
    "                    # add back the mean pixels we subtracted before\n",
    "                    gen_image = gen_image + self.vgg.mean_pixels \n",
    "                    writer.add_summary(summary, global_step=index)\n",
    "                    print('Step {}\\n   Sum: {:5.1f}'.format(index + 1, np.sum(gen_image)))\n",
    "                    print('   Loss: {:5.1f}'.format(total_loss))\n",
    "                    print('   Took: {} seconds'.format(time.time() - start_time))\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    filename = 'outputs/%d.png' % (index)\n",
    "                    save_image(filename, gen_image)\n",
    "                    myData = [[index,total_loss/np.sum(gen_image)]  ]\n",
    "                    myFile = open('/home/n/projectdl/19adam.csv', 'a')  \n",
    "                    with myFile:  \n",
    "                        writer_ = csv.writer(myFile)\n",
    "                        writer_.writerows(myData)\n",
    "                    \n",
    "\n",
    "                    if (index + 1) % 20 == 0:\n",
    "                        ###############################\n",
    "                        ## TO DO: save the variables into a checkpoint\n",
    "                        saver.save(sess, 'checkpoints/style_stranfer/style_transfer', index)\n",
    "                        ###############################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#     setup()\n",
    "    op = int(input(\"enter optimizer\"))\n",
    "#     op = 1\n",
    "    machine = StyleTransfer('/home/n/projectdl/content1.jpg', '/home/n/projectdl/color4.jpg',500,500,op)\n",
    "    machine.build(op)\n",
    "    machine.train(500)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/machrisaa/tensorflow-vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    output_img = sess.run(net['input'])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "minimize_with_lbfgs(sess, net, optimizer, init_img)\n",
    "def minimize_with_lbfgs(sess, net, optimizer, init_img):\n",
    "    if args.verbose: print('\\nMINIMIZING LOSS USING: L-BFGS OPTIMIZER')\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    sess.run(net['input'].assign(init_img))\n",
    "    optimizer.minimize(sess)\n",
    "\n",
    "\n",
    "def get_optimizer(loss):\n",
    "    print_iterations = args.print_iterations if args.verbose else 0\n",
    "    if args.optimizer == 'lbfgs':\n",
    "        optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "        loss, method='L-BFGS-B',\n",
    "        options={'maxiter': args.max_iterations,\n",
    "                  'disp': print_iterations})\n",
    "    elif args.optimizer == 'adam':\n",
    "        optimizer = tf.train.AdamOptimizer(args.learning_rate)\n",
    "    return optimizer\n",
    "\n",
    " output_img = sess.run(net['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize_with_lbfgs(sess, net, optimizer, init_img)\n",
    "def minimize_with_lbfgs(sess):\n",
    "#     if args.verbose: print('\\nMINIMIZING LOSS USING: L-BFGS OPTIMIZER')\n",
    "#     init_op = tf.global_variables_initializer()\n",
    "#     sess.run(init_op)\n",
    "    sess.run(net['input'].assign(init_img))\n",
    "    optimizer.minimize(sess)\n",
    "\n",
    "\n",
    "def get_optimizer(self):\n",
    "#     print_iterations = args.print_iterations if args.verbose else 0\n",
    "    if self.opp == 'lbfgs':\n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "        self.total_loss, method='L-BFGS-B',\n",
    "        options={'maxiter': 10})\n",
    "        self.optimizer\n",
    "\n",
    "output_img = sess.run(net['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
